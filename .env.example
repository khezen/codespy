# codespy Configuration
# Copy this file to .env and fill in your values
#
# NOTE: For advanced configuration (per-signature settings, model overrides),
# use codespy.yaml instead. See codespy.yaml for full options.
# Priority: Environment Variables > YAML Config > Defaults

# =============================================================================
# REQUIRED: GitHub Token
# =============================================================================
# Create a token at: https://github.com/settings/tokens
# Required scopes: repo (for private repos) or public_repo (for public repos only)
# Auto-discovered from: gh CLI, git credential helper, ~/.netrc
GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# =============================================================================
# LLM Configuration (choose one provider)
# =============================================================================

# Default model identifier (LiteLLM format)
# Examples:
#   - gpt-5                                          (OpenAI)
#   - gpt-4-turbo                                     (OpenAI)
#   - bedrock/anthropic.claude-opus-4-5-20251101-v1:0 (AWS Bedrock)
#   - bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0 (AWS Bedrock)
#   - bedrock/anthropic.claude-haiku-4-5-20260112-v1:0  (AWS Bedrock)
#   - claude-4-5-opus-20251101                        (Anthropic direct)
#   - claude-4-5-sonnet-20251018                      (Anthropic direct)
#   - gemini/gemini-2.5-pro                           (Google Gemini)
#   - gemini/gemini-2.5-flash                         (Google Gemini)
#   - ollama/llama-4-70b                              (Local Ollama)
DEFAULT_MODEL=gpt-5

# -----------------------------------------------------------------------------
# Option 1: OpenAI
# -----------------------------------------------------------------------------
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# -----------------------------------------------------------------------------
# Option 2: AWS Bedrock
# -----------------------------------------------------------------------------
# (credentials optional if using IAM roles or ~/.aws/credentials)
# AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
# AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
# AWS_PROFILE=default

# -----------------------------------------------------------------------------
# Option 3: Anthropic (direct)
# -----------------------------------------------------------------------------
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# -----------------------------------------------------------------------------
# Option 4: Google Gemini
# -----------------------------------------------------------------------------
# GEMINI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# -----------------------------------------------------------------------------
# Option 5: Azure OpenAI
# -----------------------------------------------------------------------------
# AZURE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# AZURE_API_BASE=https://your-resource.openai.azure.com/
# AZURE_API_VERSION=2024-02-15-preview

# =============================================================================
# Default Settings
# =============================================================================
# These apply to all signatures unless overridden per-signature

# DEFAULT_MODEL=gpt-5
# DEFAULT_MAX_ITERS=3
# DEFAULT_MAX_CONTEXT_SIZE=50000

# Enable provider-side prompt caching (reduces latency and costs)
# ENABLE_PROMPT_CACHING=true

# =============================================================================
# Output Settings
# =============================================================================

# Output format: markdown or json (default: markdown)
# OUTPUT_FORMAT=markdown

# Enable stdout output (default: true)
# OUTPUT_STDOUT=true

# Post review as GitHub PR comment (default: false)
# OUTPUT_GITHUB_PR=false

# Cache directory for cloned repositories (default: ~/.cache/codespy)
# CACHE_DIR=/path/to/cache

# =============================================================================
# Per-Signature Configuration (override via env vars)
# =============================================================================
# Use underscore (_) between signature name and setting
# Format: SIGNATURE_NAME_SETTING=value
#
# Available signatures:
#   - CODE_SECURITY      (security vulnerability detection)
#   - SUPPLY_CHAIN       (supply chain security analysis)
#   - BUG_DETECTION      (bug and logic error detection)
#   - DOC_REVIEW         (documentation review)
#   - DOMAIN_ANALYSIS    (domain expert analysis)
#   - SCOPE_IDENTIFICATION (code scope detection)
#   - DEDUPLICATION      (issue deduplication)
#   - SUMMARIZATION      (PR summary generation)
#
# Available settings per signature:
#   - ENABLED (true/false)
#   - MAX_ITERS (integer)
#   - MODEL (LiteLLM model string)
#   - MAX_CONTEXT_SIZE (integer)

# Examples:
# CODE_SECURITY_ENABLED=true
# CODE_SECURITY_MAX_ITERS=10
# CODE_SECURITY_MODEL=claude-sonnet-4-5-20250929

# SUPPLY_CHAIN_ENABLED=true

# BUG_DETECTION_ENABLED=true
# BUG_DETECTION_MAX_ITERS=5

# DOC_REVIEW_ENABLED=true
# DOC_REVIEW_MODEL=claude-haiku-4-5-20251001

# DOMAIN_ANALYSIS_ENABLED=false
# DOMAIN_ANALYSIS_MAX_ITERS=6

# SCOPE_IDENTIFICATION_ENABLED=true
# SCOPE_IDENTIFICATION_MAX_ITERS=10

# DEDUPLICATION_ENABLED=true
# DEDUPLICATION_MODEL=claude-haiku-4-5-20251001

# SUMMARIZATION_ENABLED=true
# SUMMARIZATION_MODEL=claude-haiku-4-5-20251001